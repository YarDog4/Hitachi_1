# -*- coding: utf-8 -*-
"""Pinecone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x1TNp9UXjyv9tKzyOYTCbWaZWXINyAiS
"""

# Importing what is needed to run the function
from pinecone import Pinecone
from pinecone import ServerlessSpec
import pandas as pd
import matplotlib.pyplot as plt
import time
import os
from dotenv import load_dotenv

load_dotenv()

# Establish the function category_scores that takes the text as the input
def category_scores(text, df):
    # Establish the key for pinecone
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    # Establish the index name 
    index_name = os.getenv("PINECONE_INDEX")

    # Delete and recreate index
    # pc.delete_index(index_name)
    # pc.create_index(
    #     name=index_name,
    #     dimension=1024,
    #     metric="cosine",
    #     spec=ServerlessSpec(cloud="aws", region="us-east-1")
    # )

    # Wait until index is ready
    while not pc.describe_index(index_name).status['ready']:
        time.sleep(1)

    index = pc.Index(index_name)

    # Insert input text into Pinecone, adding ID and Vec variables
    # data = [{"id": "vec1", "text": text}]
    embeddings = pc.inference.embed(
        # We will be using the multilingual e5 large model
        model="multilingual-e5-large",
        inputs=[text],
        parameters={"input_type": "passage", "truncate": "END"}
    )
    vectors = [{
        "id": str(df.iloc[0]['id']),
        "values": embeddings[0].values,
        "metadata": {"text": text}
    }]
    index.upsert(vectors=vectors, namespace="ns1")

    # Define categories
    categories = [
        "atheism", "space", "pc hardware", "windows computer",
        "for sale", "automobiles", "motorcycles", "baseball", "hockey",
        "crypto", "electronics", "medicine", "Christianity", "guns",
        "middle east", "misc politics", "misc religion", "mac hardware",
        "graphics", "windows misc"
    ]

    # Run similarity search with retry logic
    scores = {}
    for category in categories:
        query = f"Text that discusses {category}"
        embedding = pc.inference.embed(
            model="multilingual-e5-large",
            inputs=[query],
            parameters={"input_type": "query"}
        )

        # In case of an error on the query search, numbers were chosen through testing
        max_retries = 7
        retry_delay = 3
        attempt = 0
        score = 0.0

        
        # Embed the vector value as long as the max retry limit wasn't reached
        while attempt < max_retries:
            result = index.query(
                namespace="ns2",
                vector=embedding[0].values,
                top_k=3,
                include_values=False,
                include_metadata=True
            )

            # Save the value under variable score
            if result['matches']:
                score = result['matches'][0]['score']
                break
            # Retry if unsuccessful 
            else:
                attempt += 1
                time.sleep(retry_delay)

        # Append the score in scores 
        scores[category] = score
        time.sleep(4)

    # Convert to DataFrame
    df_scores = pd.DataFrame([scores])

    # Sort the DataFrame by score (descending)
    df_sorted = df_scores.T.sort_values(by=0, ascending=False)

    # Create bar plot
    fig, ax = plt.subplots(figsize=(16, 6))
    ax.bar(df_sorted.index, df_sorted[0], color="orange")
    ax.set_ylim(0.7, 0.9)
    ax.set_xlabel("Categories")
    ax.set_ylabel("Scores")
    ax.set_title("Sorted Scores")
    ax.set_xticks(range(len(df_sorted)))
    ax.set_xticklabels(df_sorted.index, rotation=90)
    fig.tight_layout()
    plt.show()
    return fig

